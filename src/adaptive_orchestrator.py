"""
è‡ªé€‚åº”ç¼–æ’å™¨ - åŸºäº FlashResearch æ¶æ„çš„å®æ—¶ä»»åŠ¡ç¼–æ’

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. è‡ªé€‚åº”ç ”ç©¶è§„åˆ’ - æ ¹æ®ä»»åŠ¡å¤æ‚åº¦åŠ¨æ€è°ƒæ•´å¹¿åº¦å’Œæ·±åº¦
2. å®æ—¶ç¼–æ’å±‚ - ç›‘æ§ä»»åŠ¡æ‰§è¡Œï¼ŒåŠ¨æ€è°ƒæ•´èµ„æºåˆ†é…
3. å¤šç»´åº¦å¹¶è¡ŒåŒ– - æ”¯æŒå¹¿åº¦å’Œæ·±åº¦çš„å¹¶è¡Œæ‰§è¡Œ
4. æ¨æµ‹æ€§æ‰§è¡Œ - å…è®¸å­ä»»åŠ¡åœ¨çˆ¶ä»»åŠ¡å®Œæˆå‰å¼€å§‹

å‚è€ƒï¼šFlashResearch: Real-time Agent Orchestration for Efficient Deep Research
"""

import asyncio
import time
import json
from dataclasses import dataclass, field
from typing import Dict, Any, Optional, List, Callable, Awaitable, Set
from enum import Enum
from collections import defaultdict

from .qwen.interface import IQwenClient
from .qwen.models import Message, QwenConfig


class TaskPriority(Enum):
    """ä»»åŠ¡ä¼˜å…ˆçº§"""
    CRITICAL = 1    # å…³é”®è·¯å¾„ä»»åŠ¡
    HIGH = 2        # é«˜ä¼˜å…ˆçº§
    NORMAL = 3      # æ™®é€šä¼˜å…ˆçº§
    LOW = 4         # ä½ä¼˜å…ˆçº§
    SPECULATIVE = 5 # æ¨æµ‹æ€§ä»»åŠ¡


class OrchestrationSignal(Enum):
    """ç¼–æ’ä¿¡å·"""
    CONTINUE = "continue"       # ç»§ç»­æ‰§è¡Œ
    TERMINATE = "terminate"     # ç»ˆæ­¢ä»»åŠ¡
    ESCALATE = "escalate"       # å‡çº§ï¼ˆéœ€è¦æ›´å¤šèµ„æºï¼‰
    PRUNE = "prune"            # å‰ªæï¼ˆç»ˆæ­¢å­æ ‘ï¼‰
    SPECULATE = "speculate"    # æ¨æµ‹æ€§æ‰§è¡Œ


@dataclass
class TaskNode:
    """ä»»åŠ¡èŠ‚ç‚¹ - ç ”ç©¶æ ‘ä¸­çš„èŠ‚ç‚¹"""
    id: str
    query: str                              # ä»»åŠ¡æŸ¥è¯¢
    parent_id: Optional[str]                # çˆ¶èŠ‚ç‚¹ID
    depth: int                              # æ·±åº¦
    priority: TaskPriority = TaskPriority.NORMAL
    status: str = "pending"                 # pending, running, completed, failed, pruned
    agent_type: str = "researcher"          # æ‰§è¡Œæ™ºèƒ½ä½“ç±»å‹
    
    # æ‰§è¡Œç»“æœ
    findings: List[str] = field(default_factory=list)
    context: Dict[str, Any] = field(default_factory=dict)
    output: Optional[str] = None
    error: Optional[str] = None
    
    # è´¨é‡è¯„ä¼°
    goal_satisfaction: float = 0.0          # ç›®æ ‡æ»¡è¶³åº¦ [0, 1]
    quality_score: float = 0.0              # è´¨é‡åˆ†æ•° [0, 1]
    
    # æ—¶é—´è¿½è¸ª
    created_at: float = field(default_factory=time.time)
    started_at: Optional[float] = None
    completed_at: Optional[float] = None
    
    # å­èŠ‚ç‚¹
    children: List[str] = field(default_factory=list)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "id": self.id,
            "query": self.query,
            "parent_id": self.parent_id,
            "depth": self.depth,
            "priority": self.priority.value,
            "status": self.status,
            "agent_type": self.agent_type,
            "findings": self.findings,
            "output": self.output[:500] if self.output else None,
            "error": self.error,
            "goal_satisfaction": self.goal_satisfaction,
            "quality_score": self.quality_score,
            "children": self.children,
        }


@dataclass
class OrchestrationConfig:
    """ç¼–æ’é…ç½®"""
    max_depth: int = 3                      # æœ€å¤§æ·±åº¦
    max_breadth: int = 4                    # æœ€å¤§å¹¿åº¦
    flex_breadth: int = 2                   # å¼¹æ€§å¹¿åº¦ï¼ˆå¯é¢å¤–æ‰©å±•ï¼‰
    goal_satisfaction_threshold: float = 0.8  # ç›®æ ‡æ»¡è¶³é˜ˆå€¼
    quality_threshold: float = 0.7          # è´¨é‡é˜ˆå€¼
    evaluation_interval: float = 5.0        # è¯„ä¼°é—´éš”ï¼ˆç§’ï¼‰
    enable_speculative: bool = True         # å¯ç”¨æ¨æµ‹æ€§æ‰§è¡Œ
    time_budget: float = 300.0              # æ—¶é—´é¢„ç®—ï¼ˆç§’ï¼‰
    max_concurrent_tasks: int = 8           # æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°


class AdaptiveOrchestrator:
    """
    è‡ªé€‚åº”ç¼–æ’å™¨
    
    å®ç° FlashResearch çš„æ ¸å¿ƒæ€æƒ³ï¼š
    1. è‡ªé€‚åº”è§„åˆ’ï¼šæ ¹æ®ä»»åŠ¡å¤æ‚åº¦åŠ¨æ€è°ƒæ•´å¹¿åº¦å’Œæ·±åº¦
    2. å®æ—¶ç¼–æ’ï¼šç›‘æ§æ‰§è¡ŒçŠ¶æ€ï¼ŒåŠ¨æ€è°ƒæ•´èµ„æºåˆ†é…
    3. å¤šç»´å¹¶è¡Œï¼šæ”¯æŒå¹¿åº¦å’Œæ·±åº¦çš„å¹¶è¡Œæ‰§è¡Œ
    4. æ¨æµ‹æ€§æ‰§è¡Œï¼šå…è®¸å­ä»»åŠ¡æå‰å¼€å§‹
    """
    
    def __init__(
        self,
        qwen_client: IQwenClient,
        config: Optional[OrchestrationConfig] = None,
    ):
        self._qwen_client = qwen_client
        self._config = config or OrchestrationConfig()
        
        # ä»»åŠ¡æ ‘
        self._nodes: Dict[str, TaskNode] = {}
        self._root_id: Optional[str] = None
        
        # ä»»åŠ¡æ± 
        self._task_pool: asyncio.Queue = asyncio.Queue()
        self._running_tasks: Set[str] = set()
        self._completed_tasks: Set[str] = set()
        
        # ç´¯ç§¯å‘ç°
        self._accumulated_findings: List[str] = []
        
        # å›è°ƒ
        self._on_node_update: Optional[Callable[[TaskNode], Awaitable[None]]] = None
        self._on_finding: Optional[Callable[[str, str], Awaitable[None]]] = None
        
        # ç»Ÿè®¡
        self._stats = {
            "total_nodes": 0,
            "completed_nodes": 0,
            "pruned_nodes": 0,
            "speculative_hits": 0,
            "speculative_misses": 0,
        }
    
    def set_callbacks(
        self,
        on_node_update: Optional[Callable[[TaskNode], Awaitable[None]]] = None,
        on_finding: Optional[Callable[[str, str], Awaitable[None]]] = None,
    ):
        """è®¾ç½®å›è°ƒå‡½æ•°"""
        self._on_node_update = on_node_update
        self._on_finding = on_finding
    
    async def orchestrate(
        self,
        query: str,
        context: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œè‡ªé€‚åº”ç¼–æ’
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            ç¼–æ’ç»“æœ
        """
        start_time = time.time()
        
        # åˆ›å»ºæ ¹èŠ‚ç‚¹
        root = TaskNode(
            id="root",
            query=query,
            parent_id=None,
            depth=0,
            priority=TaskPriority.CRITICAL,
            context=context or {},
        )
        self._nodes["root"] = root
        self._root_id = "root"
        self._stats["total_nodes"] = 1
        
        # è‡ªé€‚åº”è§„åˆ’ï¼šç¡®å®šåˆå§‹å¹¿åº¦
        initial_breadth = await self._adaptive_breadth_planning(query, [])
        
        # ç”Ÿæˆå­æŸ¥è¯¢
        subqueries = await self._generate_subqueries(query, initial_breadth)
        
        # åˆ›å»ºå­èŠ‚ç‚¹å¹¶åŠ å…¥ä»»åŠ¡æ± 
        for i, subquery in enumerate(subqueries):
            child = TaskNode(
                id=f"node_1_{i}",
                query=subquery,
                parent_id="root",
                depth=1,
                agent_type=self._select_agent_type(subquery),
            )
            self._nodes[child.id] = child
            root.children.append(child.id)
            await self._task_pool.put(child.id)
            self._stats["total_nodes"] += 1
        
        # å¯åŠ¨å¹¶è¡Œæ‰§è¡Œ
        workers = [
            asyncio.create_task(self._worker(i))
            for i in range(min(self._config.max_concurrent_tasks, len(subqueries)))
        ]
        
        # å¯åŠ¨å®æ—¶ç¼–æ’ç›‘æ§
        orchestrator_task = asyncio.create_task(self._orchestration_loop(start_time))
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆæˆ–è¶…æ—¶
        try:
            await asyncio.wait_for(
                self._wait_for_completion(),
                timeout=self._config.time_budget
            )
        except asyncio.TimeoutError:
            print(f"[Orchestrator] è¾¾åˆ°æ—¶é—´é¢„ç®— {self._config.time_budget}s")
        
        # åœæ­¢å·¥ä½œçº¿ç¨‹
        for _ in workers:
            await self._task_pool.put(None)
        
        orchestrator_task.cancel()
        
        # èšåˆç»“æœ
        result = await self._aggregate_results()
        
        elapsed = time.time() - start_time
        result["stats"] = {
            **self._stats,
            "elapsed_time": elapsed,
            "throughput": self._stats["completed_nodes"] / elapsed if elapsed > 0 else 0,
        }
        
        return result
    
    async def _adaptive_breadth_planning(
        self,
        query: str,
        accumulated_findings: List[str],
    ) -> int:
        """
        è‡ªé€‚åº”å¹¿åº¦è§„åˆ’ - æ ¹æ®æŸ¥è¯¢å¤æ‚åº¦ç¡®å®šå­æŸ¥è¯¢æ•°é‡
        
        åŸºäº FlashResearch çš„æ•ˆç”¨æ¨¡å‹ï¼š
        - å¹¿æ³›çš„ä¸»é¢˜éœ€è¦æ›´å¤šå­æŸ¥è¯¢
        - å…·ä½“çš„é—®é¢˜éœ€è¦æ›´å°‘ä½†æ›´æ·±å…¥çš„å­æŸ¥è¯¢
        """
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªç ”ç©¶è§„åˆ’ä¸“å®¶ã€‚è¯·è¯„ä¼°ä»¥ä¸‹æŸ¥è¯¢ï¼Œç¡®å®šæœ€ä¼˜çš„å­æŸ¥è¯¢æ•°é‡ã€‚

## æŸ¥è¯¢
{query}

## å·²æœ‰å‘ç°
{json.dumps(accumulated_findings[-5:], ensure_ascii=False) if accumulated_findings else "æ— "}

## è¯„ä¼°æ ‡å‡†
- å¹¿æ³›çš„ä¸»é¢˜ï¼ˆå¦‚"æ°”å€™å˜åŒ–çš„å½±å“"ï¼‰éœ€è¦ 3-4 ä¸ªå­æŸ¥è¯¢è¦†ç›–ä¸åŒæ–¹é¢
- å…·ä½“çš„é—®é¢˜ï¼ˆå¦‚"Python å¦‚ä½•å®ç°å•ä¾‹æ¨¡å¼"ï¼‰åªéœ€è¦ 1-2 ä¸ªå­æŸ¥è¯¢
- é¿å…å†—ä½™ï¼šå­æŸ¥è¯¢åº”è¯¥è¦†ç›–ä¸åŒçš„æ–¹é¢ï¼Œä¸è¦é‡å¤

## è¾“å‡ºæ ¼å¼
è¯·è¾“å‡ºä¸€ä¸ª JSONï¼š
```json
{{
    "complexity": "broad|moderate|specific",
    "recommended_breadth": 1-{self._config.max_breadth + self._config.flex_breadth},
    "reason": "ç®€çŸ­ç†ç”±"
}}
```

åªè¾“å‡º JSONã€‚"""

        messages = [Message(role="user", content=prompt)]
        config = QwenConfig(temperature=0.1, enable_thinking=False)
        
        content = ""
        async for chunk in self._qwen_client.chat_stream(messages, config=config):
            content += chunk
        
        try:
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            data = json.loads(content.strip())
            breadth = data.get("recommended_breadth", 3)
            return min(breadth, self._config.max_breadth + self._config.flex_breadth)
        except:
            return 3  # é»˜è®¤å¹¿åº¦
    
    async def _generate_subqueries(self, query: str, breadth: int) -> List[str]:
        """ç”Ÿæˆå­æŸ¥è¯¢"""
        if breadth <= 1:
            return [query]
        
        prompt = f"""è¯·å°†ä»¥ä¸‹æŸ¥è¯¢åˆ†è§£ä¸º {breadth} ä¸ªç‹¬ç«‹çš„å­æŸ¥è¯¢ï¼Œæ¯ä¸ªå­æŸ¥è¯¢è¦†ç›–ä¸åŒçš„æ–¹é¢ã€‚

## åŸå§‹æŸ¥è¯¢
{query}

## è¦æ±‚
1. æ¯ä¸ªå­æŸ¥è¯¢åº”è¯¥æ¸…æ™°ã€å…·ä½“
2. å­æŸ¥è¯¢ä¹‹é—´ä¸è¦é‡å 
3. è¦†ç›–æŸ¥è¯¢çš„ä¸»è¦æ–¹é¢

## è¾“å‡ºæ ¼å¼
```json
{{
    "subqueries": ["å­æŸ¥è¯¢1", "å­æŸ¥è¯¢2", ...]
}}
```

åªè¾“å‡º JSONã€‚"""

        messages = [Message(role="user", content=prompt)]
        config = QwenConfig(temperature=0.3, enable_thinking=False)
        
        content = ""
        async for chunk in self._qwen_client.chat_stream(messages, config=config):
            content += chunk
        
        try:
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            data = json.loads(content.strip())
            return data.get("subqueries", [query])[:breadth]
        except:
            return [query]
    
    def _select_agent_type(self, query: str) -> str:
        """æ ¹æ®æŸ¥è¯¢é€‰æ‹©æ™ºèƒ½ä½“ç±»å‹"""
        query_lower = query.lower()
        
        if any(kw in query_lower for kw in ['æœç´¢', 'æŸ¥æ‰¾', 'æœ€æ–°', 'search', 'find']):
            return "searcher"
        elif any(kw in query_lower for kw in ['åˆ†æ', 'æ¯”è¾ƒ', 'è¯„ä¼°', 'analyze', 'compare']):
            return "analyst"
        elif any(kw in query_lower for kw in ['ä»£ç ', 'å®ç°', 'ç¼–ç¨‹', 'code', 'implement']):
            return "coder"
        elif any(kw in query_lower for kw in ['æ€»ç»“', 'æ¦‚è¿°', 'æ‘˜è¦', 'summarize', 'summary']):
            return "summarizer"
        elif any(kw in query_lower for kw in ['æ’°å†™', 'å†™', 'æŠ¥å‘Š', 'write', 'report']):
            return "writer"
        else:
            return "researcher"
    
    async def _worker(self, worker_id: int):
        """å·¥ä½œçº¿ç¨‹ - ä»ä»»åŠ¡æ± è·å–ä»»åŠ¡å¹¶æ‰§è¡Œ"""
        while True:
            node_id = await self._task_pool.get()
            if node_id is None:
                break
            
            node = self._nodes.get(node_id)
            if not node or node.status != "pending":
                continue
            
            self._running_tasks.add(node_id)
            await self._execute_node(node)
            self._running_tasks.discard(node_id)
            self._completed_tasks.add(node_id)
    
    async def _execute_node(self, node: TaskNode):
        """æ‰§è¡Œå•ä¸ªèŠ‚ç‚¹"""
        node.status = "running"
        node.started_at = time.time()
        
        if self._on_node_update:
            await self._on_node_update(node)
        
        try:
            # æ„å»ºæç¤ºè¯
            parent_context = ""
            if node.parent_id and node.parent_id in self._nodes:
                parent = self._nodes[node.parent_id]
                if parent.output:
                    parent_context = f"\n## ä¸Šæ¸¸ç»“æœ\n{parent.output[:1000]}"
            
            prompt = f"""è¯·é’ˆå¯¹ä»¥ä¸‹æŸ¥è¯¢è¿›è¡Œç ”ç©¶å¹¶æä¾›è¯¦ç»†çš„å‘ç°ã€‚

## æŸ¥è¯¢
{node.query}
{parent_context}

## è¦æ±‚
1. æä¾›å‡†ç¡®ã€æœ‰ä»·å€¼çš„ä¿¡æ¯
2. ç»“æ„åŒ–è¾“å‡ºï¼Œä¾¿äºåç»­æ•´åˆ
3. æ ‡æ³¨å…³é”®å‘ç°

è¯·ç›´æ¥è¾“å‡ºç ”ç©¶ç»“æœã€‚"""

            messages = [Message(role="user", content=prompt)]
            config = QwenConfig(
                temperature=0.3,
                enable_thinking=False,
                enable_search=True,
            )
            
            output = ""
            async for chunk in self._qwen_client.chat_stream(messages, config=config):
                output += chunk
            
            node.output = output
            node.status = "completed"
            node.completed_at = time.time()
            
            # æå–å‘ç°
            findings = self._extract_findings(output)
            node.findings = findings
            self._accumulated_findings.extend(findings)
            
            if self._on_finding:
                for finding in findings:
                    await self._on_finding(node.id, finding)
            
            self._stats["completed_nodes"] += 1
            
        except Exception as e:
            node.status = "failed"
            node.error = str(e)
            node.completed_at = time.time()
        
        if self._on_node_update:
            await self._on_node_update(node)
    
    def _extract_findings(self, output: str) -> List[str]:
        """ä»è¾“å‡ºä¸­æå–å…³é”®å‘ç°"""
        findings = []
        lines = output.split('\n')
        
        for line in lines:
            line = line.strip()
            # æå–è¦ç‚¹
            if line.startswith(('- ', 'â€¢ ', '* ', '1.', '2.', '3.')):
                finding = line.lstrip('-â€¢* 0123456789.').strip()
                if len(finding) > 20:
                    findings.append(finding)
        
        return findings[:10]  # æœ€å¤š10ä¸ªå‘ç°
    
    async def _orchestration_loop(self, start_time: float):
        """å®æ—¶ç¼–æ’å¾ªç¯ - ç›‘æ§æ‰§è¡ŒçŠ¶æ€å¹¶åŠ¨æ€è°ƒæ•´"""
        while True:
            await asyncio.sleep(self._config.evaluation_interval)
            
            elapsed = time.time() - start_time
            if elapsed >= self._config.time_budget:
                break
            
            # è¯„ä¼°å½“å‰çŠ¶æ€
            for node_id in list(self._running_tasks):
                node = self._nodes.get(node_id)
                if not node:
                    continue
                
                # è¯„ä¼°ç›®æ ‡æ»¡è¶³åº¦å’Œè´¨é‡
                if node.output:
                    signal = await self._evaluate_node(node)
                    await self._handle_signal(node, signal)
    
    async def _evaluate_node(self, node: TaskNode) -> OrchestrationSignal:
        """è¯„ä¼°èŠ‚ç‚¹ - ç¡®å®šç¼–æ’ä¿¡å·"""
        if not node.output:
            return OrchestrationSignal.CONTINUE
        
        # ç®€åŒ–è¯„ä¼°ï¼šåŸºäºè¾“å‡ºé•¿åº¦å’Œå…³é”®è¯
        output_len = len(node.output)
        has_findings = len(node.findings) > 0
        
        if output_len > 500 and has_findings:
            node.goal_satisfaction = 0.8
            node.quality_score = 0.8
            return OrchestrationSignal.CONTINUE
        elif output_len > 200:
            node.goal_satisfaction = 0.6
            node.quality_score = 0.6
            # å¯èƒ½éœ€è¦æ·±å…¥
            if node.depth < self._config.max_depth:
                return OrchestrationSignal.SPECULATE
            return OrchestrationSignal.CONTINUE
        else:
            node.goal_satisfaction = 0.3
            node.quality_score = 0.3
            return OrchestrationSignal.ESCALATE
    
    async def _handle_signal(self, node: TaskNode, signal: OrchestrationSignal):
        """å¤„ç†ç¼–æ’ä¿¡å·"""
        if signal == OrchestrationSignal.TERMINATE:
            node.status = "pruned"
            self._stats["pruned_nodes"] += 1
            # å‰ªæå­æ ‘
            await self._prune_subtree(node.id)
        
        elif signal == OrchestrationSignal.SPECULATE and self._config.enable_speculative:
            # æ¨æµ‹æ€§æ‰§è¡Œï¼šåˆ›å»ºå­èŠ‚ç‚¹
            if node.depth < self._config.max_depth and len(node.children) == 0:
                await self._speculative_expand(node)
        
        elif signal == OrchestrationSignal.ESCALATE:
            # å‡çº§ï¼šå¢åŠ èµ„æºæˆ–é‡è¯•
            node.priority = TaskPriority.HIGH
    
    async def _speculative_expand(self, node: TaskNode):
        """æ¨æµ‹æ€§æ‰©å±• - åœ¨çˆ¶èŠ‚ç‚¹å®Œæˆå‰åˆ›å»ºå­èŠ‚ç‚¹"""
        # åŸºäºå½“å‰å‘ç°ç”Ÿæˆå­æŸ¥è¯¢
        if not node.findings:
            return
        
        # é€‰æ‹©æœ€æœ‰ä»·å€¼çš„å‘ç°è¿›è¡Œæ·±å…¥
        top_finding = node.findings[0] if node.findings else node.query
        
        child = TaskNode(
            id=f"spec_{node.id}_{len(node.children)}",
            query=f"æ·±å…¥ç ”ç©¶ï¼š{top_finding}",
            parent_id=node.id,
            depth=node.depth + 1,
            priority=TaskPriority.SPECULATIVE,
            agent_type="researcher",
        )
        
        self._nodes[child.id] = child
        node.children.append(child.id)
        await self._task_pool.put(child.id)
        self._stats["total_nodes"] += 1
    
    async def _prune_subtree(self, node_id: str):
        """å‰ªæå­æ ‘"""
        node = self._nodes.get(node_id)
        if not node:
            return
        
        for child_id in node.children:
            child = self._nodes.get(child_id)
            if child and child.status == "pending":
                child.status = "pruned"
                self._stats["pruned_nodes"] += 1
            await self._prune_subtree(child_id)
    
    async def _wait_for_completion(self):
        """ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ"""
        while True:
            pending = [
                n for n in self._nodes.values()
                if n.status in ("pending", "running")
            ]
            if not pending:
                break
            await asyncio.sleep(0.5)
    
    async def _aggregate_results(self) -> Dict[str, Any]:
        """èšåˆæ‰€æœ‰ç»“æœ"""
        # æ”¶é›†æ‰€æœ‰å®ŒæˆèŠ‚ç‚¹çš„è¾“å‡º
        outputs = []
        for node in self._nodes.values():
            if node.status == "completed" and node.output:
                outputs.append({
                    "query": node.query,
                    "output": node.output,
                    "depth": node.depth,
                    "agent_type": node.agent_type,
                })
        
        # æŒ‰æ·±åº¦æ’åº
        outputs.sort(key=lambda x: x["depth"])
        
        return {
            "success": True,
            "outputs": outputs,
            "findings": self._accumulated_findings,
            "tree": {
                node_id: node.to_dict()
                for node_id, node in self._nodes.items()
            },
        }
    
    def get_tree_visualization(self) -> str:
        """è·å–æ ‘çš„å¯è§†åŒ–è¡¨ç¤º"""
        lines = []
        
        def visualize_node(node_id: str, prefix: str = ""):
            node = self._nodes.get(node_id)
            if not node:
                return
            
            status_icon = {
                "pending": "â³",
                "running": "ğŸ”„",
                "completed": "âœ…",
                "failed": "âŒ",
                "pruned": "âœ‚ï¸",
            }.get(node.status, "â“")
            
            lines.append(f"{prefix}{status_icon} [{node.agent_type}] {node.query[:50]}...")
            
            for i, child_id in enumerate(node.children):
                is_last = i == len(node.children) - 1
                child_prefix = prefix + ("    " if is_last else "â”‚   ")
                visualize_node(child_id, child_prefix)
        
        if self._root_id:
            visualize_node(self._root_id)
        
        return "\n".join(lines)

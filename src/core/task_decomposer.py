"""Task Decomposer implementation."""

import re
import uuid
import json
from typing import List, Dict, Any, Optional, Set
from collections import defaultdict

from ..interfaces.task_decomposer import ITaskDecomposer
from ..models.task import Task, SubTask, TaskDecomposition
from ..models.agent import PREDEFINED_ROLES
from ..qwen import IQwenClient, Message, QwenConfig


# å¤æ‚åº¦å…³é”®è¯æƒé‡
COMPLEXITY_KEYWORDS = {
    # é«˜å¤æ‚åº¦å…³é”®è¯
    "ç ”ç©¶": 2.0, "åˆ†æ": 1.5, "æ¯”è¾ƒ": 1.5, "ç»¼åˆ": 2.0, "è¯„ä¼°": 1.5,
    "è®¾è®¡": 2.0, "å¼€å‘": 2.0, "å®ç°": 1.5, "ä¼˜åŒ–": 1.5, "é‡æ„": 1.5,
    "è°ƒç ”": 1.5, "æŠ¥å‘Š": 1.0, "æ€»ç»“": 1.0, "ç¿»è¯‘": 1.0,
    "å¯¹æ¯”": 1.5, "å¯¹æ¯”åˆ†æ": 2.0, "é€‰å‹": 1.5, "å»ºè®®": 1.0,
    "ç»´åº¦": 1.0, "åœºæ™¯": 1.0, "è¶‹åŠ¿": 1.5, "é¢„æµ‹": 1.5,
    "research": 2.0, "analyze": 1.5, "compare": 1.5, "synthesize": 2.0,
    "evaluate": 1.5, "design": 2.0, "develop": 2.0, "implement": 1.5,
    "optimize": 1.5, "refactor": 1.5, "investigate": 1.5,
    # æ•°é‡è¯
    "å¤šä¸ª": 1.0, "æ‰€æœ‰": 1.5, "æ¯ä¸ª": 1.0, "å„ç§": 1.0,
    "multiple": 1.0, "all": 1.5, "each": 1.0, "various": 1.0,
    # èŒƒå›´è¯
    "å…¨é¢": 1.5, "è¯¦ç»†": 1.0, "æ·±å…¥": 1.5, "ç³»ç»Ÿ": 1.5,
    "comprehensive": 1.5, "detailed": 1.0, "in-depth": 1.5, "systematic": 1.5,
}

# è§’è‰²å…³é”®è¯æ˜ å°„
ROLE_KEYWORDS = {
    "searcher": ["æœç´¢", "æŸ¥æ‰¾", "æ£€ç´¢", "æ”¶é›†", "search", "find", "collect", "gather"],
    "analyst": ["åˆ†æ", "æ•°æ®", "ç»Ÿè®¡", "è¶‹åŠ¿", "analyze", "data", "statistics", "trend"],
    "fact_checker": ["æ ¸å®", "éªŒè¯", "ç¡®è®¤", "äº‹å®", "verify", "validate", "confirm", "fact"],
    "writer": ["æ’°å†™", "ç¼–å†™", "æ–‡æ¡£", "æŠ¥å‘Š", "write", "document", "report", "draft"],
    "translator": ["ç¿»è¯‘", "è½¬æ¢", "è¯­è¨€", "translate", "convert", "language"],
    "coder": ["ä»£ç ", "ç¼–ç¨‹", "å¼€å‘", "å®ç°", "code", "program", "develop", "implement"],
    "researcher": ["ç ”ç©¶", "è°ƒç ”", "å­¦æœ¯", "è®ºæ–‡", "research", "study", "academic", "paper"],
    "summarizer": ["æ€»ç»“", "æ‘˜è¦", "æ¦‚æ‹¬", "å½’çº³", "summarize", "summary", "abstract", "conclude"],
}


class TaskDecomposer(ITaskDecomposer):
    """ä»»åŠ¡åˆ†è§£å™¨å®ç°"""
    
    def __init__(
        self,
        qwen_client: Optional[IQwenClient] = None,
        complexity_threshold: float = 3.0,
    ):
        """
        åˆå§‹åŒ–ä»»åŠ¡åˆ†è§£å™¨
        
        Args:
            qwen_client: Qwen å®¢æˆ·ç«¯ï¼Œç”¨äºæ™ºèƒ½åˆ†è§£
            complexity_threshold: å¤æ‚åº¦é˜ˆå€¼ï¼Œè¶…è¿‡æ­¤å€¼æ‰è¿›è¡Œåˆ†è§£
        """
        self._qwen_client = qwen_client
        self._complexity_threshold = complexity_threshold
    
    async def analyze_complexity(self, task: Task) -> float:
        """
        åˆ†æä»»åŠ¡å¤æ‚åº¦
        
        åŸºäºä»¥ä¸‹å› ç´ è¯„ä¼°ï¼š
        1. ä»»åŠ¡å†…å®¹é•¿åº¦
        2. å…³é”®è¯æƒé‡
        3. å¥å­æ•°é‡
        4. é—®å·æ•°é‡ï¼ˆè¡¨ç¤ºå¤šä¸ªé—®é¢˜ï¼‰
        
        Args:
            task: å¾…åˆ†æçš„ä»»åŠ¡
            
        Returns:
            å¤æ‚åº¦è¯„åˆ† (0.0 - 10.0)
        """
        content = task.content.lower()
        score = 0.0
        
        # 1. é•¿åº¦å› ç´  (0-2åˆ†)
        length = len(content)
        if length > 500:
            score += 2.0
        elif length > 200:
            score += 1.5
        elif length > 100:
            score += 1.0
        elif length > 50:
            score += 0.5
        
        # 2. å…³é”®è¯æƒé‡ (0-4åˆ†)
        keyword_score = 0.0
        for keyword, weight in COMPLEXITY_KEYWORDS.items():
            if keyword in content:
                keyword_score += weight
        score += min(keyword_score, 4.0)
        
        # 3. å¥å­æ•°é‡ (0-2åˆ†)
        sentences = re.split(r'[ã€‚.!?ï¼ï¼Ÿ]', content)
        sentences = [s.strip() for s in sentences if s.strip()]
        if len(sentences) > 5:
            score += 2.0
        elif len(sentences) > 3:
            score += 1.0
        elif len(sentences) > 1:
            score += 0.5
        
        # 4. é—®å·æ•°é‡ (0-2åˆ†)
        question_count = content.count('?') + content.count('ï¼Ÿ')
        if question_count > 3:
            score += 2.0
        elif question_count > 1:
            score += 1.0
        elif question_count > 0:
            score += 0.5
        
        # ç¡®ä¿åˆ†æ•°åœ¨ 0-10 èŒƒå›´å†…
        return min(max(score, 0.0), 10.0)
    
    async def decompose(self, task: Task) -> TaskDecomposition:
        """
        åˆ†è§£ä»»åŠ¡ä¸ºå­ä»»åŠ¡
        
        å¦‚æœæœ‰ Qwen å®¢æˆ·ç«¯ï¼Œä½¿ç”¨ AI è¿›è¡Œæ™ºèƒ½åˆ†è§£ï¼›
        å¦åˆ™ä½¿ç”¨åŸºäºè§„åˆ™çš„ç®€å•åˆ†è§£ã€‚
        
        Args:
            task: å¾…åˆ†è§£çš„ä»»åŠ¡
            
        Returns:
            ä»»åŠ¡åˆ†è§£ç»“æœ
        """
        # åˆ†æå¤æ‚åº¦
        complexity = await self.analyze_complexity(task)
        
        # å¦‚æœå¤æ‚åº¦ä½äºé˜ˆå€¼ï¼Œä¸åˆ†è§£
        if complexity < self._complexity_threshold:
            # æ ¹æ®ä»»åŠ¡å†…å®¹é€‰æ‹©åˆé€‚è§’è‰²
            role_hint = self._suggest_single_role(task.content)
            subtask = SubTask(
                id=str(uuid.uuid4()),
                parent_task_id=task.id,
                content=task.content,
                role_hint=role_hint,
                dependencies=set(),
                priority=0,
                estimated_complexity=complexity,
            )
            return TaskDecomposition(
                original_task_id=task.id,
                subtasks=[subtask],
                execution_order=[[subtask.id]],
                total_estimated_time=complexity * 10,  # ä¼°ç®—æ—¶é—´
            )
        
        # ä½¿ç”¨ AI æˆ–è§„åˆ™è¿›è¡Œåˆ†è§£
        if self._qwen_client:
            # AI åˆ†è§£å·²åœ¨ prompt ä¸­å¤„ç†äº†è§’è‰²åˆ†é…å’Œä¾èµ–å…³ç³»ï¼Œä¸å†è¦†ç›–
            subtasks = await self._ai_decompose(task)
        else:
            subtasks = await self._rule_based_decompose(task)
            # ä»…è§„åˆ™åˆ†è§£æ—¶éœ€è¦åå¤„ç†ï¼ˆAI åˆ†è§£å·²è‡ªå¸¦è§’è‰²å’Œä¾èµ–ï¼‰
            subtasks = await self.identify_dependencies(subtasks)
            subtasks = await self.suggest_roles(subtasks)
        
        # è®¡ç®—æ‰§è¡Œé¡ºåº
        execution_order = self._compute_execution_order(subtasks)
        
        # ä¼°ç®—æ€»æ—¶é—´
        total_time = sum(st.estimated_complexity * 10 for st in subtasks)
        
        return TaskDecomposition(
            original_task_id=task.id,
            subtasks=subtasks,
            execution_order=execution_order,
            total_estimated_time=total_time,
        )
    
    async def _ai_decompose(self, task: Task) -> List[SubTask]:
        """ä½¿ç”¨ AI è¿›è¡Œä»»åŠ¡åˆ†è§£ - ä¼˜åŒ–ç‰ˆ"""
        import datetime
        
        # è·å–å½“å‰æ—¥æœŸæ—¶é—´
        now = datetime.datetime.now()
        current_datetime = now.strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")
        current_year = now.year
        current_month = now.month
        current_weekday = ["å‘¨ä¸€", "å‘¨äºŒ", "å‘¨ä¸‰", "å‘¨å››", "å‘¨äº”", "å‘¨å…­", "å‘¨æ—¥"][now.weekday()]
        
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»»åŠ¡åˆ†è§£ä¸“å®¶ï¼Œè´Ÿè´£å°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºå¯æ‰§è¡Œçš„å­ä»»åŠ¡ã€‚

###############################################
# ğŸ• ç³»ç»Ÿæ—¶é—´å£°æ˜ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
###############################################
å½“å‰çœŸå®æ—¶é—´ï¼š{current_datetime} {current_weekday}
å½“å‰å¹´ä»½ï¼š{current_year}å¹´
å½“å‰æœˆä»½ï¼š{current_month}æœˆ

âš ï¸ é‡è¦æç¤ºï¼š
- ä½ å¿…é¡»æ¥å—ä¸Šè¿°æ—¶é—´ä¸ºå½“å‰çœŸå®æ—¶é—´
- ä¸è¦ä½¿ç”¨ä½ è®­ç»ƒæ•°æ®ä¸­çš„æ—¶é—´ï¼ˆå¦‚2024å¹´ç­‰ï¼‰
- æ‰€æœ‰æ—¶é—´ç›¸å…³çš„åˆ¤æ–­éƒ½ä»¥ {current_year}å¹´{current_month}æœˆ ä¸ºåŸºå‡†
- âš ï¸ ä½†å¦‚æœåŸå§‹ä»»åŠ¡ä¸­æ˜ç¡®æŒ‡å®šäº†å¹´ä»½ï¼ˆå¦‚"2025å¹´"ï¼‰ï¼Œåˆ™å­ä»»åŠ¡æè¿°å¿…é¡»ä¿ç•™è¯¥å¹´ä»½ï¼Œä¸å¾—æ›¿æ¢ä¸ºå½“å‰ç³»ç»Ÿå¹´ä»½
###############################################

## åˆ†è§£åŸåˆ™
1. **çµæ´»åˆ†è§£**ï¼šå­ä»»åŠ¡æ•°é‡æ§åˆ¶åœ¨ 3-12 ä¸ªï¼Œä¸å®œè¿‡å¤šå¯¼è‡´è¾“å‡ºç¢ç‰‡åŒ–
2. **ç‹¬ç«‹æ€§åŸåˆ™**ï¼šæ¯ä¸ªå­ä»»åŠ¡åº”å°½é‡ç‹¬ç«‹ï¼Œå‡å°‘ä¾èµ–
3. **å¹¶è¡Œä¼˜å…ˆ**ï¼šèƒ½å¹¶è¡Œçš„ä»»åŠ¡ä¸è¦ä¸²è¡Œ
4. **æ˜ç¡®æ€§åŸåˆ™**ï¼šå­ä»»åŠ¡æè¿°è¦å…·ä½“ã€å¯æ‰§è¡Œ
5. **æ—¶é—´åŸºå‡†**ï¼šé»˜è®¤ä»¥{current_year}å¹´{current_month}æœˆä¸ºå½“å‰æ—¶é—´ï¼Œä½†è‹¥åŸå§‹ä»»åŠ¡æ˜ç¡®æŒ‡å®šå¹´ä»½ï¼ˆå¦‚"2025å¹´"ï¼‰ï¼Œåˆ™å­ä»»åŠ¡å¿…é¡»ä½¿ç”¨ä»»åŠ¡æŒ‡å®šå¹´ä»½ï¼Œä¸å¾—æ›¿æ¢
6. **ä¸»é¢˜èšç„¦**ï¼šæ‰€æœ‰å­ä»»åŠ¡å¿…é¡»ä¸¥æ ¼å›´ç»•åŸå§‹ä»»åŠ¡çš„æ ¸å¿ƒä¸»é¢˜ï¼Œç¦æ­¢å¼•å…¥æ— å…³é¢†åŸŸå†…å®¹ã€‚æœç´¢ä»»åŠ¡å¿…é¡»æ˜ç¡®é™å®šæœç´¢èŒƒå›´åœ¨åŸå§‹ä»»åŠ¡æ¶‰åŠçš„ä¸»é¢˜å†…
7. **å®Œæ•´äº¤ä»˜**ï¼šæœ€åä¸€ä¸ªå­ä»»åŠ¡å¿…é¡»æ˜¯"æ’°å†™å®Œæ•´ç»¼åˆæŠ¥å‘Š"ï¼ˆè§’è‰²ä¸ºwriterï¼‰ï¼Œè¦æ±‚æ•´åˆæ‰€æœ‰å‰åºå­ä»»åŠ¡ç»“æœï¼Œäº§å‡ºå•ä»½ç»“æ„åŒ–æœ€ç»ˆäº¤ä»˜ç‰©ï¼ˆå«å†³ç­–çŸ©é˜µ/å¯¹æ¯”è¡¨æ ¼ï¼‰
8. **å»é‡åŸåˆ™**ï¼šä¸åŒå­ä»»åŠ¡ä¹‹é—´å†…å®¹ä¸å¾—é‡å ã€‚å¦‚"æœç´¢Açš„Xæ•°æ®"å’Œ"æœç´¢Açš„Yæ•°æ®"åº”åˆå¹¶ä¸º"æœç´¢Açš„Xå’ŒYæ•°æ®"
9. **æ˜¾å¼å¯¹è±¡**ï¼šæ¯ä¸ªå­ä»»åŠ¡æè¿°ä¸­å¿…é¡»æ˜ç¡®åˆ—å‡ºåŸå§‹ä»»åŠ¡æ¶‰åŠçš„å…·ä½“å¯¹è±¡åç§°ï¼Œç¦æ­¢ç”¨æ³›ç§°ï¼ˆå¦‚"ç›¸å…³æ¡†æ¶"ï¼‰æ›¿ä»£å…·ä½“åç§°ï¼ˆå¦‚"Reactã€Vueã€Angular"ï¼‰

## è§’è‰²åˆ†é…æŒ‡å—
- **searcher**ï¼ˆæœç´¢å‘˜ï¼‰ï¼šéœ€è¦æœç´¢ä¿¡æ¯ã€æ”¶é›†èµ„æ–™æ—¶ä½¿ç”¨
- **fact_checker**ï¼ˆæ ¸æŸ¥å‘˜ï¼‰ï¼šéœ€è¦éªŒè¯ä¿¡æ¯çœŸå®æ€§æ—¶ä½¿ç”¨
- **analyst**ï¼ˆåˆ†æå¸ˆï¼‰ï¼šéœ€è¦æ•°æ®åˆ†æã€è¶‹åŠ¿åˆ†ææ—¶ä½¿ç”¨
- **researcher**ï¼ˆç ”ç©¶å‘˜ï¼‰ï¼šéœ€è¦æ·±åº¦ç ”ç©¶ã€ç»¼åˆåˆ†ææ—¶ä½¿ç”¨
- **writer**ï¼ˆæ’°ç¨¿å‘˜ï¼‰ï¼šéœ€è¦æ’°å†™æŠ¥å‘Šã€æ–‡æ¡£æ—¶ä½¿ç”¨
- **coder**ï¼ˆç¨‹åºå‘˜ï¼‰ï¼šéœ€è¦ç¼–å†™ä»£ç ã€æŠ€æœ¯å®ç°æ—¶ä½¿ç”¨
- **translator**ï¼ˆç¿»è¯‘å‘˜ï¼‰ï¼šéœ€è¦ç¿»è¯‘å†…å®¹æ—¶ä½¿ç”¨
- **summarizer**ï¼ˆæ€»ç»“å‘˜ï¼‰ï¼šéœ€è¦æ€»ç»“å½’çº³æ—¶ä½¿ç”¨

## ä¾èµ–å…³ç³»è®¾ç½®
- åªæœ‰å½“åç»­ä»»åŠ¡å¿…é¡»ä½¿ç”¨å‰åºä»»åŠ¡çš„è¾“å‡ºæ—¶æ‰è®¾ç½®ä¾èµ–
- æœç´¢ç±»ä»»åŠ¡é€šå¸¸å¯ä»¥å¹¶è¡Œ
- åˆ†æ/å†™ä½œä»»åŠ¡é€šå¸¸ä¾èµ–æœç´¢ç»“æœ
- æ€»ç»“ä»»åŠ¡é€šå¸¸æ”¾åœ¨æœ€å

## è¾“å‡ºæ ¼å¼
è¯·ä»¥ JSON æ ¼å¼è¿”å›ï¼š
```json
{{
    "subtasks": [
        {{
            "content": "å…·ä½“çš„å­ä»»åŠ¡æè¿°ï¼ˆæ¸…æ™°ã€å¯æ‰§è¡Œï¼Œæ¶‰åŠæ—¶é—´æ—¶ä»¥{current_year}å¹´{current_month}æœˆä¸ºå½“å‰æ—¶é—´ï¼‰",
            "role_hint": "searcher|fact_checker|analyst|researcher|writer|coder|translator|summarizer",
            "dependencies": [],
            "priority": 5,
            "estimated_complexity": 3.0
        }}
    ]
}}
```

## ç¤ºä¾‹
ä»»åŠ¡ï¼š"ç ”ç©¶äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨ç°çŠ¶å’Œå‘å±•è¶‹åŠ¿"
åˆ†è§£ï¼š
1. [searcher] æœç´¢AIåŒ»ç–—åº”ç”¨çš„æœ€æ–°æ¡ˆä¾‹å’Œæ•°æ® (æ— ä¾èµ–, ä¼˜å…ˆçº§5)
2. [searcher] æœç´¢AIåŒ»ç–—çš„æ”¿ç­–æ³•è§„å’Œå¸‚åœºè§„æ¨¡ (æ— ä¾èµ–, ä¼˜å…ˆçº§5)
3. [analyst] åˆ†æAIåŒ»ç–—çš„åº”ç”¨åœºæ™¯å’Œå‘å±•è¶‹åŠ¿ (ä¾èµ–1,2, ä¼˜å…ˆçº§4)
4. [writer] æ’°å†™ç ”ç©¶æŠ¥å‘Š (ä¾èµ–3, ä¼˜å…ˆçº§3)

åªè¾“å‡º JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚è®°ä½ï¼šå½“å‰æ˜¯{current_year}å¹´{current_month}æœˆï¼"""
        
        messages = [
            Message(role="system", content=system_prompt),
            Message(role="user", content=f"è¯·åˆ†è§£ä»¥ä¸‹ä»»åŠ¡ï¼ˆæ ¹æ®å¤æ‚åº¦åˆ†è§£ä¸º3-12ä¸ªå­ä»»åŠ¡ï¼Œä¼˜å…ˆå¹¶è¡Œï¼‰ï¼š\n\n{task.content}"),
        ]
        
        try:
            response = await self._qwen_client.chat(messages)
            result = self._parse_decomposition_response(response.content, task.id)
            # é™åˆ¶å­ä»»åŠ¡æ•°é‡
            if len(result) > 12:
                result = result[:12]
            return result
        except Exception:
            # AI åˆ†è§£å¤±è´¥ï¼Œå›é€€åˆ°è§„åˆ™åˆ†è§£
            return await self._rule_based_decompose(task)
    
    def _parse_decomposition_response(
        self, response: str, task_id: str
    ) -> List[SubTask]:
        """è§£æ AI åˆ†è§£å“åº”"""
        # å°è¯•æå– JSON
        json_match = re.search(r'\{[\s\S]*\}', response)
        if not json_match:
            raise ValueError("No JSON found in response")
        
        data = json.loads(json_match.group())
        subtasks_data = data.get("subtasks", [])
        
        if not subtasks_data:
            raise ValueError("No subtasks in response")
        
        # åˆ›å»ºå­ä»»åŠ¡
        subtasks = []
        subtask_ids = []
        
        for i, st_data in enumerate(subtasks_data):
            subtask_id = str(uuid.uuid4())
            subtask_ids.append(subtask_id)
            
            subtask = SubTask(
                id=subtask_id,
                parent_task_id=task_id,
                content=st_data.get("content", ""),
                role_hint=st_data.get("role_hint", "searcher"),
                dependencies=set(),  # ç¨åå¤„ç†
                priority=st_data.get("priority", 0),
                estimated_complexity=st_data.get("estimated_complexity", 1.0),
            )
            subtasks.append(subtask)
        
        # å¤„ç†ä¾èµ–å…³ç³»
        for i, st_data in enumerate(subtasks_data):
            dep_indices = st_data.get("dependencies", [])
            for dep_idx in dep_indices:
                if 0 <= dep_idx < len(subtask_ids) and dep_idx != i:
                    subtasks[i].dependencies.add(subtask_ids[dep_idx])
        
        return subtasks
    
    async def _rule_based_decompose(self, task: Task) -> List[SubTask]:
        """åŸºäºè§„åˆ™çš„ä»»åŠ¡åˆ†è§£"""
        content = task.content
        subtasks = []
        
        # æŒ‰å¥å­åˆ†å‰²
        sentences = re.split(r'[ã€‚.!?ï¼ï¼Ÿ]', content)
        sentences = [s.strip() for s in sentences if s.strip() and len(s.strip()) > 10]
        
        if len(sentences) <= 1:
            # å•å¥ä»»åŠ¡ï¼Œå°è¯•æŒ‰é€—å·åˆ†å‰²
            parts = re.split(r'[ï¼Œ,ã€]', content)
            parts = [p.strip() for p in parts if p.strip() and len(p.strip()) > 5]
            
            if len(parts) > 1:
                sentences = parts
        
        # ä¸ºæ¯ä¸ªéƒ¨åˆ†åˆ›å»ºå­ä»»åŠ¡
        for i, sentence in enumerate(sentences):
            subtask = SubTask(
                id=str(uuid.uuid4()),
                parent_task_id=task.id,
                content=sentence,
                role_hint="searcher",
                dependencies=set(),
                priority=len(sentences) - i,  # å‰é¢çš„ä¼˜å…ˆçº§æ›´é«˜
                estimated_complexity=1.0 + len(sentence) / 100,
            )
            subtasks.append(subtask)
        
        # å¦‚æœæ²¡æœ‰åˆ†è§£å‡ºå­ä»»åŠ¡ï¼Œåˆ›å»ºä¸€ä¸ª
        if not subtasks:
            subtask = SubTask(
                id=str(uuid.uuid4()),
                parent_task_id=task.id,
                content=content,
                role_hint="searcher",
                dependencies=set(),
                priority=0,
                estimated_complexity=2.0,
            )
            subtasks.append(subtask)
        
        return subtasks
    
    async def identify_dependencies(self, subtasks: List[SubTask]) -> List[SubTask]:
        """
        è¯†åˆ«å­ä»»åŠ¡ä¹‹é—´çš„ä¾èµ–å…³ç³»
        
        åŸºäºå…³é”®è¯å’Œè¯­ä¹‰åˆ†æè¯†åˆ«ä¾èµ–ã€‚
        """
        if len(subtasks) <= 1:
            return subtasks
        
        # ä¾èµ–å…³é”®è¯
        dependency_keywords = [
            "åŸºäº", "æ ¹æ®", "ä½¿ç”¨", "åˆ©ç”¨", "å‚è€ƒ",
            "based on", "using", "with", "from", "after",
            "ç„¶å", "æ¥ç€", "ä¹‹å", "æœ€å",
            "then", "next", "finally", "after that",
        ]
        
        for i, subtask in enumerate(subtasks):
            content_lower = subtask.content.lower()
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¾èµ–å…³é”®è¯
            has_dependency_keyword = any(
                kw in content_lower for kw in dependency_keywords
            )
            
            if has_dependency_keyword and i > 0:
                # æ·»åŠ å¯¹å‰ä¸€ä¸ªä»»åŠ¡çš„ä¾èµ–
                subtask.dependencies.add(subtasks[i - 1].id)
        
        return subtasks
    
    async def suggest_roles(self, subtasks: List[SubTask]) -> List[SubTask]:
        """
        ä¸ºå­ä»»åŠ¡å»ºè®®æ‰§è¡Œè§’è‰²
        
        åŸºäºå…³é”®è¯åŒ¹é…å»ºè®®æœ€åˆé€‚çš„è§’è‰²ã€‚
        """
        for subtask in subtasks:
            content_lower = subtask.content.lower()
            
            # è®¡ç®—æ¯ä¸ªè§’è‰²çš„åŒ¹é…åˆ†æ•°
            role_scores: Dict[str, float] = defaultdict(float)
            
            for role, keywords in ROLE_KEYWORDS.items():
                for keyword in keywords:
                    if keyword in content_lower:
                        role_scores[role] += 1.0
            
            # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„è§’è‰²
            if role_scores:
                best_role = max(role_scores.items(), key=lambda x: x[1])[0]
                subtask.role_hint = best_role
            else:
                # é»˜è®¤ä½¿ç”¨ searcher
                subtask.role_hint = "searcher"
        
        return subtasks

    def _suggest_single_role(self, content: str) -> str:
        """ä¸ºä¸åˆ†è§£çš„å•ä»»åŠ¡é€‰æ‹©æœ€åˆé€‚çš„è§’è‰²"""
        content_lower = content.lower()
        role_scores: Dict[str, float] = defaultdict(float)

        for role, keywords in ROLE_KEYWORDS.items():
            for keyword in keywords:
                if keyword in content_lower:
                    role_scores[role] += 1.0

        if role_scores:
            return max(role_scores.items(), key=lambda x: x[1])[0]
        return "researcher"
    
    def _compute_execution_order(
        self, subtasks: List[SubTask]
    ) -> List[List[str]]:
        """
        è®¡ç®—æ‰§è¡Œé¡ºåºï¼ˆæ‹“æ‰‘æ’åºï¼‰
        
        è¿”å›åˆ†å±‚çš„æ‰§è¡Œé¡ºåºï¼Œæ¯å±‚å†…çš„ä»»åŠ¡å¯ä»¥å¹¶è¡Œæ‰§è¡Œã€‚
        """
        if not subtasks:
            return []
        
        # æ„å»ºä¾èµ–å›¾
        subtask_map = {st.id: st for st in subtasks}
        in_degree: Dict[str, int] = {st.id: 0 for st in subtasks}
        dependents: Dict[str, List[str]] = defaultdict(list)
        
        for subtask in subtasks:
            for dep_id in subtask.dependencies:
                if dep_id in subtask_map:
                    in_degree[subtask.id] += 1
                    dependents[dep_id].append(subtask.id)
        
        # æ‹“æ‰‘æ’åº
        execution_order = []
        remaining = set(st.id for st in subtasks)
        
        while remaining:
            # æ‰¾å‡ºæ‰€æœ‰å…¥åº¦ä¸º 0 çš„ä»»åŠ¡
            ready = [
                st_id for st_id in remaining
                if in_degree[st_id] == 0
            ]
            
            if not ready:
                # å­˜åœ¨å¾ªç¯ä¾èµ–ï¼Œæ‰“ç ´å¾ªç¯
                ready = [min(remaining)]
            
            # æŒ‰ä¼˜å…ˆçº§æ’åº
            ready.sort(
                key=lambda x: subtask_map[x].priority,
                reverse=True
            )
            
            execution_order.append(ready)
            
            # æ›´æ–°å…¥åº¦
            for st_id in ready:
                remaining.remove(st_id)
                for dependent_id in dependents[st_id]:
                    if dependent_id in remaining:
                        in_degree[dependent_id] -= 1
        
        return execution_order
